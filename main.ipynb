{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "Episode 2\n",
      "Episode 3\n",
      "Episode 4\n"
     ]
    }
   ],
   "source": [
    "# We create our gym environment \n",
    "# env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Number of episodes to run\n",
    "n_explore_episodes = 0\n",
    "n_episodes = 20\n",
    "max_steps = 20000\n",
    "\n",
    "# How frequently to write the current episode (if 0 it will never write it)\n",
    "write_frequency = 1\n",
    "# After how many episodes the game should be drawn (if 0 it will never draw)\n",
    "draw_frequency = 0\n",
    "\n",
    "total_steps = 0\n",
    "scores = np.zeros(n_episodes)\n",
    "rewards = np.zeros(n_episodes)\n",
    "lines = np.zeros(n_episodes)\n",
    "# We define our agent\n",
    "agent = Agent()\n",
    "\n",
    "for ep in range(n_episodes):\n",
    "    \n",
    "    if write_frequency != 0:\n",
    "        if ep % write_frequency == 0:\n",
    "            print(\"Episode \" + str(ep + 1))\n",
    "    \n",
    "\n",
    "    explore = ep < n_explore_episodes\n",
    "\n",
    "    draw = False\n",
    "    if not draw_frequency == 0:\n",
    "        draw = ep % draw_frequency == draw_frequency - 1\n",
    "    \n",
    "    steps, score, reward, line = agent.run_episode(draw_screen=draw and not explore, always_explore=explore, max_steps=max_steps)\n",
    "    total_steps += steps\n",
    "    scores[ep] = score\n",
    "    rewards[ep] = reward\n",
    "    lines[ep] = line\n",
    "\n",
    "    if total_steps >= agent.batch_size:\n",
    "        agent.train()\n",
    "\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.xlabel(\"Episode #\")\n",
    "plt.ylabel(\"Total score\")\n",
    "plt.savefig('keyboard_input_scores.png')\n",
    "plt.show()\n",
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episode #\")\n",
    "plt.ylabel(\"Total reward (heuristic)\")\n",
    "plt.savefig('keyboard_input_rewards.png')\n",
    "plt.show()\n",
    "plt.plot(lines)\n",
    "plt.xlabel(\"Episode #\")\n",
    "plt.ylabel(\"Total lines cleared\")\n",
    "plt.savefig('keyboard_input_lines.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "Episode 2\n",
      "Episode 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m draw_frequency \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     21\u001b[0m     draw \u001b[39m=\u001b[39m ep \u001b[39m%\u001b[39m draw_frequency \u001b[39m==\u001b[39m draw_frequency \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 22\u001b[0m agent\u001b[39m.\u001b[39;49mrun_episode(draw_screen\u001b[39m=\u001b[39;49mdraw \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m explore, always_explore\u001b[39m=\u001b[39;49mexplore)\n",
      "File \u001b[1;32mc:\\Users\\ahamb\\OneDrive\\Documents\\College\\CS138\\TransferTetris\\agent.py:94\u001b[0m, in \u001b[0;36mAgent.run_episode\u001b[1;34m(self, draw_screen, always_explore)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore_episode(current_state, action, reward, next_state, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m draw_screen: \n\u001b[1;32m---> 94\u001b[0m         time\u001b[39m.\u001b[39;49msleep(DRAW_WAIT_TIME)\n\u001b[0;32m     95\u001b[0m         game\u001b[39m.\u001b[39mredraw()\n\u001b[0;32m     96\u001b[0m \u001b[39mexcept\u001b[39;00m GameOver:\n\u001b[0;32m     97\u001b[0m     \u001b[39m# next_state = game.matris.current_state()\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Number of episodes to run\n",
    "n_explore_episodes = 0\n",
    "n_episodes = 500\n",
    "\n",
    "# How frequently to write the current episode (if 0 it will never write it)\n",
    "write_frequency = 1\n",
    "# After how many episodes the game should be drawn (if 0 it will never draw)\n",
    "draw_frequency = 1\n",
    "\n",
    "for ep in range(n_episodes):\n",
    "    \n",
    "    if write_frequency != 0:\n",
    "        if ep % write_frequency == 0:\n",
    "            print(\"Episode \" + str(ep + 1))\n",
    "    \n",
    "\n",
    "    explore = ep < n_explore_episodes\n",
    "\n",
    "    draw = False\n",
    "    if not draw_frequency == 0:\n",
    "        draw = ep % draw_frequency == draw_frequency - 1\n",
    "    agent.run_episode(draw_screen=draw and not explore, always_explore=explore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.display.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m draw_frequency \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     26\u001b[0m     draw \u001b[39m=\u001b[39m ep \u001b[39m%\u001b[39m draw_frequency \u001b[39m==\u001b[39m draw_frequency \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 27\u001b[0m testAgent\u001b[39m.\u001b[39;49mrun_episode(draw_screen\u001b[39m=\u001b[39;49mdraw \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m explore, always_explore\u001b[39m=\u001b[39;49mexplore)\n",
      "File \u001b[1;32mc:\\Users\\ahamb\\OneDrive\\Documents\\College\\CS138\\TransferTetris\\agent.py:79\u001b[0m, in \u001b[0;36mAgent.run_episode\u001b[1;34m(self, draw_screen, always_explore)\u001b[0m\n\u001b[0;32m     76\u001b[0m     current_state \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mmatris\u001b[39m.\u001b[39mcurrent_state()\n\u001b[0;32m     78\u001b[0m steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 79\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_action(current_state, always_explore\u001b[39m=\u001b[39;49malways_explore)\n\u001b[0;32m     80\u001b[0m rotation, position \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_to_tuple(action)\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m draw_screen:\n",
      "File \u001b[1;32mc:\\Users\\ahamb\\OneDrive\\Documents\\College\\CS138\\TransferTetris\\agent.py:119\u001b[0m, in \u001b[0;36mAgent.compute_action\u001b[1;34m(self, current_state, always_explore)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m always_explore \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexploration_proba:\n\u001b[0;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_actions))\n\u001b[1;32m--> 119\u001b[0m q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49marray([current_state]), verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39margmax(q_values)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2346\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2344\u001b[0m callbacks\u001b[39m.\u001b[39mon_predict_begin()\n\u001b[0;32m   2345\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2346\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2347\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2348\u001b[0m         \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1304\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1304\u001b[0m     data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset)\n\u001b[0;32m   1305\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[0;32m   1306\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:499\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[0;32m    498\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:703\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    699\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    700\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    701\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    702\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 703\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[0;32m    705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:742\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    739\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(fulltype\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[0;32m    740\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types)\n\u001b[0;32m    741\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 742\u001b[0m gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3439\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3437\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3438\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3439\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3440\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMakeIterator\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, dataset, iterator)\n\u001b[0;32m   3441\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3442\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We create our gym environment \n",
    "# env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Number of episodes to run\n",
    "n_explore_episodes = 0\n",
    "n_episodes = 20\n",
    "\n",
    "# How frequently to write the current episode (if 0 it will never write it)\n",
    "write_frequency = 0\n",
    "# After how many episodes the game should be drawn (if 0 it will never draw)\n",
    "draw_frequency = 1\n",
    "# We define our agent\n",
    "testAgent = Agent()\n",
    "\n",
    "for ep in range(n_episodes):\n",
    "    \n",
    "    if write_frequency != 0:\n",
    "        if ep % write_frequency == 0:\n",
    "            print(\"Episode \" + str(ep + 1))\n",
    "    \n",
    "\n",
    "    explore = ep < n_explore_episodes\n",
    "\n",
    "    draw = False\n",
    "    if not draw_frequency == 0:\n",
    "        draw = ep % draw_frequency == draw_frequency - 1\n",
    "    testAgent.run_episode(draw_screen=draw and not explore, always_explore=explore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
