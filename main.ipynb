{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "0.9900498337491681\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m draw_frequency \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     30\u001b[0m     draw \u001b[39m=\u001b[39m ep \u001b[39m%\u001b[39m draw_frequency \u001b[39m==\u001b[39m draw_frequency \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 31\u001b[0m steps, score, reward \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mrun_episode(draw_screen\u001b[39m=\u001b[39mdraw \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m explore, always_explore\u001b[39m=\u001b[39mexplore)\n\u001b[0;32m     32\u001b[0m total_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m steps\n\u001b[0;32m     33\u001b[0m scores[ep] \u001b[39m=\u001b[39m score\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# We create our gym environment \n",
    "# env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Number of episodes to run\n",
    "n_explore_episodes = 0\n",
    "n_episodes = 500\n",
    "\n",
    "# How frequently to write the current episode (if 0 it will never write it)\n",
    "write_frequency = 1\n",
    "# After how many episodes the game should be drawn (if 0 it will never draw)\n",
    "draw_frequency = 0\n",
    "\n",
    "total_steps = 0\n",
    "scores = np.zeros(n_episodes)\n",
    "rewards = np.zeros(n_episodes)\n",
    "lines = np.zeros(n_episodes)\n",
    "# We define our agent\n",
    "agent = Agent()\n",
    "\n",
    "for ep in range(n_episodes):\n",
    "    \n",
    "    if write_frequency != 0:\n",
    "        if ep % write_frequency == 0:\n",
    "            print(\"Episode \" + str(ep + 1))\n",
    "    \n",
    "\n",
    "    explore = ep < n_explore_episodes\n",
    "\n",
    "    draw = False\n",
    "    if not draw_frequency == 0:\n",
    "        draw = ep % draw_frequency == draw_frequency - 1\n",
    "    steps, score, reward, line = agent.run_episode(draw_screen=draw and not explore, always_explore=explore)\n",
    "    total_steps += steps\n",
    "    scores[ep] = score\n",
    "    rewards[ep] = reward\n",
    "    lines[ep] = line\n",
    "\n",
    "    if total_steps >= agent.batch_size:\n",
    "        agent.train()\n",
    "\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.xlabel(\"Episode #\")\n",
    "plt.ylabel(\"Total score\")\n",
    "plt.savefig('pqueue_heur_square_scores.png')\n",
    "plt.show()\n",
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episode #\")\n",
    "plt.ylabel(\"Total reward (heuristic)\")\n",
    "plt.savefig('pqueue_heur_square_rewards.png')\n",
    "plt.show()\n",
    "plt.plot(lines)\n",
    "plt.xlabel(\"Episode #\")\n",
    "plt.ylabel(\"Total lines cleared\")\n",
    "plt.savefig('pqueue_heur_square_lines.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "0.006670903306255456\n",
      "Episode 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m draw_frequency \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     21\u001b[0m     draw \u001b[39m=\u001b[39m ep \u001b[39m%\u001b[39m draw_frequency \u001b[39m==\u001b[39m draw_frequency \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 22\u001b[0m agent\u001b[39m.\u001b[39;49mrun_episode(draw_screen\u001b[39m=\u001b[39;49mdraw \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m explore, always_explore\u001b[39m=\u001b[39;49mexplore)\n",
      "File \u001b[1;32mc:\\Users\\ahamb\\OneDrive\\Documents\\College\\CS138\\TransferTetris\\agent.py:81\u001b[0m, in \u001b[0;36mAgent.run_episode\u001b[1;34m(self, draw_screen, always_explore)\u001b[0m\n\u001b[0;32m     79\u001b[0m rotation, position \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_to_tuple(action)\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m draw_screen:\n\u001b[1;32m---> 81\u001b[0m     time\u001b[39m.\u001b[39msleep(DRAW_WAIT_TIME)\n\u001b[0;32m     82\u001b[0m score, reward \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mmatris\u001b[39m.\u001b[39mcomputer_update(rotation, position)\n\u001b[0;32m     83\u001b[0m reward \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Number of episodes to run\n",
    "n_explore_episodes = 0\n",
    "n_episodes = 500\n",
    "\n",
    "# How frequently to write the current episode (if 0 it will never write it)\n",
    "write_frequency = 1\n",
    "# After how many episodes the game should be drawn (if 0 it will never draw)\n",
    "draw_frequency = 1\n",
    "\n",
    "for ep in range(n_episodes):\n",
    "    \n",
    "    if write_frequency != 0:\n",
    "        if ep % write_frequency == 0:\n",
    "            print(\"Episode \" + str(ep + 1))\n",
    "    \n",
    "\n",
    "    explore = ep < n_explore_episodes\n",
    "\n",
    "    draw = False\n",
    "    if not draw_frequency == 0:\n",
    "        draw = ep % draw_frequency == draw_frequency - 1\n",
    "    agent.run_episode(draw_screen=draw and not explore, always_explore=explore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.display.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
